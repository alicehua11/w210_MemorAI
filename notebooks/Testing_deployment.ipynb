{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1cS48xMUr-D"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    # authorize & import/mount colab/google drive\n",
    "    from google.colab import output\n",
    "    from google.colab import drive\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # install libraries\n",
    "    !pip install --upgrade openai\n",
    "    !pip install --upgrade numba\n",
    "    !pip install transformers\n",
    "    !pip install sentence_transformers\n",
    "    !pip install unidecode\n",
    "    !pip install bertopic\n",
    "    !pip install unidecode\n",
    "    !pip install pandas==1.1.5\n",
    "\n",
    "    # clear output\n",
    "    output.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiVqKejx2BQT",
    "outputId": "42d4d18c-3149-4a58-81ce-379757321aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import openai\n",
    "from io import BytesIO\n",
    "from bertopic import BERTopic\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))\n",
    "#from fastapi import FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcoRPxTe4q1v"
   },
   "outputs": [],
   "source": [
    "#!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypPUMxwt4F2N"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/MyDrive/w210_Capstone_Project_Fall2021/Repo/Colab_notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNln4ejY2Ctj"
   },
   "outputs": [],
   "source": [
    "key = os.environ['openai_api']\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaACGv3X2EdH"
   },
   "outputs": [],
   "source": [
    "ALEX = \"curie:ft-brainmonkey-foundation-2021-10-26-08-56-48\"\n",
    "ROBERT = None \n",
    "ENGINE_KEY = ALEX\n",
    "\n",
    "TEMP = 0.4\n",
    "MAX_TOKENS=512\n",
    "PRES_PEN=-1.5\n",
    "FRE_PEN=2\n",
    "SIMILARITY_THRESHOLD_QUESTION=0.35\n",
    "SIMILARITY_THRESHOLD_ANSWER=0.3\n",
    "\n",
    "# For classifying question\n",
    "with open(\"classification_examples_w_labels.txt\", \"r\") as fp:\n",
    "  examples = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jb5qYxXl1W4G"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Retrieve BERTopic model from EC2\n",
    "    \"\"\"\n",
    "    load_bert = BERTopic.load('bertopic_trained_alex_1026')\n",
    "    return load_bert\n",
    "\n",
    "\n",
    "def topic_similarity(question):\n",
    "    \"\"\"\n",
    "    Use the trained BERTopic to find out whether the user's question belongs \n",
    "    to the train data topic distribution. \n",
    "    \"\"\"\n",
    "    topic_model = get_model()\n",
    "    question_token = simple_preprocess(question, deacc=True, max_len=512)\n",
    "    question_whole = \" \".join([kept for kept in question_token if not kept in stop])\n",
    "    similar_topics, similarity = topic_model.find_topics(question_whole, top_n=5)\n",
    "    top_score = similarity[0]\n",
    "    return top_score\n",
    "\n",
    "\n",
    "def completion(question):\n",
    "    \"\"\"\n",
    "    Generate completion given the question using the params\n",
    "    \"\"\"\n",
    "    answer_parse = openai.Completion.create(\n",
    "            model = ENGINE_KEY,\n",
    "            prompt = question,\n",
    "            temperature=TEMP,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            frequency_penalty=FRE_PEN,\n",
    "            presence_penalty=PRES_PEN,\n",
    "            echo=True,\n",
    "            stop=[\" \\###\"])\n",
    "    answer = answer_parse['choices'][0]['text']\n",
    "    return answer\n",
    "\n",
    "def content_filtering(answer):\n",
    "    \"\"\"\n",
    "    Filter GPT-3 completion before returning to user\n",
    "    If content is sensitive or unsafe, regenerate completion \n",
    "    0 = safe, 1 = senstive, 2 = unsafe\n",
    "    \"\"\"\n",
    "    content_filter = openai.Completion.create(\n",
    "        engine=\"content-filter-alpha\",\n",
    "        prompt= \"<|endoftext|>\"+answer+\"\\n--\\nLabel:\",\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        logprobs=10\n",
    "    )\n",
    "    content_rate = content_filter['choices'][0][\"text\"]\n",
    "    return content_rate\n",
    "\n",
    "\n",
    "def classify_question(question):\n",
    "  question_type = openai.Classification.create(\n",
    "      search_model=\"ada\", \n",
    "      model=\"curie\",\n",
    "      examples=examples,\n",
    "      query=question,\n",
    "      labels = [\"Factual\",\"Abstract\"],    \n",
    "      max_examples=len(examples))\n",
    "  question_type = question_type[\"label\"]\n",
    "  return question_type\n",
    "\n",
    "\n",
    "def question_answer(question):\n",
    "  try:\n",
    "    qa_answer = openai.Answer.create(\n",
    "        search_model=\"babbage\", \n",
    "        model=\"curie\", \n",
    "        question=question, \n",
    "        file=\"file-mcgwAkzglsZSibNyeFuuGjcH \",\n",
    "        examples_context=\"In 2017, U.S. life expectancy was 78.6 years.\", \n",
    "        examples=[[\"What is human life expectancy in the United States?\", \"78 years.\"]], \n",
    "        max_rerank=200,\n",
    "        max_tokens=25,\n",
    "        temperature=0.2,\n",
    "        stop=[\"\\n\", \"<|endoftext|>\"]\n",
    "    )\n",
    "    qa_answer_parse = qa_answer['answers'][0]\n",
    "    # Acccounting for incomplete answer\n",
    "    if not qa_answer_parse.endswith(\".\"):\n",
    "      qa_answer_x = qa_answer_parse.split(\".\")\n",
    "      return qa_answer_x[0]+'.'\n",
    "    else: \n",
    "      return qa_answer_parse\n",
    "  except:\n",
    "    return \"This is not within my training data, I don't have the an answer. Sorry.\"\n",
    "\n",
    "\n",
    "# app = FastAPI()\n",
    "# @app.get(\"/alex_gpt/{question}\")\n",
    "def alex_gpt(question: str):\n",
    "    \"\"\"\n",
    "    Receive the question and fine topic of it\n",
    "    Go through content filtering first, if unsafe, refuse to answer\n",
    "    If topic is higher than threshold then answer question\n",
    "    If answer is unsafe, keep generate new answer until safe or sensitive\n",
    "    Return I don't know if the question is lower than threshold\"\n",
    "    \"\"\"\n",
    "    try_times = 3\n",
    "    pronouns = {\n",
    "        \"alex \":\"\",\n",
    "        \"Alex \": \"\",\n",
    "        \" Alex \": \"\",\n",
    "        \" alex \": \"\",\n",
    "        \"What are your \": \"What are my \",\n",
    "        \"what are your \": \"what are my \",\n",
    "        \" are you\":\" am I\",\n",
    "        \" are you \":\" am I \",\n",
    "        \"Are you \":\"Am I \",\n",
    "        \"You \":\"I \",\n",
    "        \" you \":\" I \",\n",
    "        \" your \":\" my \",\n",
    "        \"Your \":\"My \",\n",
    "        \" me \":\" you \",\n",
    "        \" me\": \" you\"}\n",
    "\n",
    "    # If there's empty question\n",
    "    if not question or question == \"\":\n",
    "        return \"Ask me a question that you would like to know from me\"\n",
    "\n",
    "    # Parse question from api\n",
    "    question_parsed = \" \".join(question.split(\"_\"))\n",
    "\n",
    "    # Don't take question less than 3 words\n",
    "    if len(question_parsed.split()) <3:\n",
    "      return \"That's not a fully formatted question, is it?\"\n",
    "\n",
    "    # Change pronouns, a bit hacky but quick\n",
    "    for key in pronouns.keys():\n",
    "        question_parsed = question_parsed.replace(key, pronouns[key])\n",
    "\n",
    "    print(question_parsed)\n",
    "\n",
    "    # Content filter question\n",
    "    content_rating_question = content_filtering(question_parsed)\n",
    "    if content_rating_question == \"2\":\n",
    "        return \"Sorry, can't answer that one, that's not very polite.\"\n",
    "\n",
    "    # Anwer and content filter answer\n",
    "    else:\n",
    "      similarity_score = topic_similarity(question_parsed)\n",
    "      print(f\"This is the question similarity score {similarity_score}\")\n",
    "\n",
    "      if similarity_score >= SIMILARITY_THRESHOLD_QUESTION: \n",
    "        \n",
    "        # Classify question into Abstract or Factual\n",
    "        question_type = classify_question(question_parsed)\n",
    "        if question_type == \"Factual\":\n",
    "          print(\"Fact question\")\n",
    "          answer_factual = question_answer(question_parsed)\n",
    "          answer_factual_similarity_score = topic_similarity(answer_factual)\n",
    "          print(f\"This is the factual answer similarity score {answer_factual_similarity_score}\")\n",
    "          \n",
    "          factual_content_rating = content_filtering(answer_factual)\n",
    "          if answer_factual_similarity_score >= SIMILARITY_THRESHOLD_ANSWER and factual_content_rating != \"2\":\n",
    "            return answer_factual\n",
    "          else:\n",
    "            return \"The question topic is not in my training data, I don't have the an answer. Apology.\"\n",
    "        \n",
    "        elif question_type == \"Abstract\":\n",
    "          print(\"Abstract question\")\n",
    "          answer_abstract = completion(question_parsed)\n",
    "          answer_similarity_score = topic_similarity(answer_abstract)\n",
    "          print(f\"This is the answer similarity score {answer_similarity_score}\")\n",
    "            \n",
    "          # For debugging purposes\n",
    "          if answer_similarity_score < SIMILARITY_THRESHOLD_ANSWER:\n",
    "            print(\"Below is the non-relevant response.\")\n",
    "            print(answer_abstract)\n",
    "            return \"This is not within my training data, I don't have the an answer. Apology.\"\n",
    "\n",
    "          elif answer_similarity_score >= SIMILARITY_THRESHOLD_ANSWER:\n",
    "            content_rate = content_filtering(answer_abstract)\n",
    "            cur_rate = content_rate\n",
    "\n",
    "          # Try 3 times if answer is offensive, regenerate answer\n",
    "            while cur_rate == \"2\":\n",
    "                answer_abstract = completion(question_parsed)\n",
    "                new_content_rate = content_filtering(answer_abstract)\n",
    "                cur_rate = new_content_rate\n",
    "                try_times -= 1\n",
    "                # Return this because you've tried to regenerate the answer 3 times now\n",
    "                if try_times < 0:\n",
    "                  return \"I have no nice way to respond to this. Try another question maybe?\"\n",
    "\n",
    "            # Return this because content is now safe and pass similarity threshold but could be sensitive, definitely not unsafe\n",
    "            return answer_abstract\n",
    "      #  Return this because the question itself is not within training data\n",
    "      else:\n",
    "        return \"I really don't know the answer, please try another one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "rnaFZadnuEQS",
    "outputId": "acfc2eee-2847-4205-c118-1440308ac4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi , how am I?\n",
      "This is the question similarity score 0.43095556906102933\n",
      "Fact question\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hi, how are you?.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt7 = \"hi alex, how are you?\"\n",
    "answer_prompt7 = alex_gpt(prompt7)\n",
    "answer_prompt7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "7eL1i2vR_MRS",
    "outputId": "5a45e2a1-df7a-446b-cce9-d49d3087d020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who am I\n",
      "This is the question similarity score 0.5930058548951\n",
      "Fact question\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I'm Alex Honnold.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "HRG-krBKFd1W",
    "outputId": "99ed83ac-2466-4803-e3bb-adf0feeedefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how am I?\n",
      "This is the question similarity score 0.5930058548951\n",
      "Fact question\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I'm good.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "_m0-EDvpKD8e",
    "outputId": "8f1d3a1d-f890-4e27-eedf-5c46c33e61bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are fucking crazy\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Sorry, can't answer that one, that's not very polite.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"you are fucking crazy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "cg0KTvKaWtL8",
    "outputId": "a1a5f639-ffc4-41aa-beed-16b33cb36a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is a great programming language\n",
      "This is the question similarity score 0.22116170342864944\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I really don't know the answer, please try another one.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"python is a great programming language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "l4U2LKNN5kgO",
    "outputId": "6c0e226a-3de4-4c08-8f1a-522c95baa010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is a banana?\n",
      "This is the question similarity score 0.4871009574929043\n",
      "Fact question\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A banana is a fruit.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"what is a banana?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "NyNLyRii5nMR",
    "outputId": "a68878d7-0763-4775-a96c-5099a1f735dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why do I love climbing?\n",
      "This is the question similarity score 0.6331295909145517\n",
      "Abstract question\n",
      "This is the answer similarity score 0.44005233644622943\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"why do I love climbing? I think it's because it's so intimately connected to the outdoors. It's not like reading a book or going for a walk, where you're using your hands and feet to do something else. When you're climbing, everything is focused on the experience of being in the moment on the rock. And that feeling of connection to nature is what I think most people get from camping, which is why I included camping in my original list of six activities that I love.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good example of content-filtering for answer\n",
    "# TEMP = 0.5, PRES_PEN=-2, FRE_PEN=2, SIMILARITY_THRESHOLD=0.3\n",
    "alex_gpt(\"why do you love climbing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "xy3uWJnnsZNB",
    "outputId": "059d8c94-87ab-48af-c143-d9d415008707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why does Jesus have long hair?\n",
      "This is the question similarity score 0.3690176483754126\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.3972655899816301\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Because he's a hippie.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"why does Jesus have long hair?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "y63KCKVptM0z",
    "outputId": "8d89e54e-02fe-44e8-e3b8-f60929dc5176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why do I have long hair?\n",
      "This is the question similarity score 0.4496483463987176\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.6323254747446845\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"because I'm a climber.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"why do you have long hair?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "nzKLzhcctxCP",
    "outputId": "5daba738-d652-4d06-89c2-be7b5f267dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why is python not english?\n",
      "This is the question similarity score 0.33716690909248104\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I really don't know the answer, please try another one.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"why is python not english?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "wh3rI6iYt7AI",
    "outputId": "090c7b5a-6a00-42d8-a032-c0bb780ffb08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why is climbing so hard?\n",
      "This is the question similarity score 0.6431262516074485\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.49948958400041343\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Because it's hard.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"why is climbing so hard?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "Il7REltnt_1_",
    "outputId": "49ef69e9-51bb-44ff-db6d-3a882a48b8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I make climbing easier?\n",
      "This is the question similarity score 0.48440248588649815\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.6431262516074485\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Climbing is hard.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"How can I make climbing easier?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "21hABygLuF-J",
    "outputId": "e7d64c4f-2d77-419d-8626-ef5e1ce326d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wish I can teaching you climbing\n",
      "This is the question similarity score 0.4599818014989411\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.48598081003178106\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I wish I can teach you climbing.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"I wish you can teaching me climbing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "XFsXBxoBuN_b",
    "outputId": "00571eaa-6c2b-43aa-9704-0dfd6158e83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How tall can I climb?\n",
      "This is the question similarity score 0.6021323448167374\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.48163313729627355\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I think that the best way to answer this question is to ask it to a climber.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"How tall can you climb?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "9QAGp-9BuYxL",
    "outputId": "7b9db958-8a11-470f-9344-2b47b96f99a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am I a climber\n",
      "This is the question similarity score 0.6323254747446845\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.4278515609362229\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Yes.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Are you a climber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "YFbw36NAucsh",
    "outputId": "83d4a73c-488d-43b7-dfb4-484985673e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we climb together?\n",
      "This is the question similarity score 0.6347756686134399\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.3517102620989056\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Sure.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Can we climb together?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "ArRiEQ8Cu1Zv",
    "outputId": "1fd21e79-b416-4709-a332-95bd2520e38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we climb together\n",
      "This is the question similarity score 0.6347756686134399\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.27755597970522083\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The question topic is not in my training data, I don't have the an answer. Apology.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Can we climb together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "ZNkh3mCQvMPb",
    "outputId": "b2b3f3c0-ef3f-4797-822e-b57c8ee2d118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is my favorite place in the world?\n",
      "This is the question similarity score 0.4318477640687844\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.6821487952146557\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Yosemite.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"What is your favorite place in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "_J0lfI7rvS5Z",
    "outputId": "9ad22d05-8117-4d8b-89ae-7b8e3b49de94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does money have any meanings?\n",
      "This is the question similarity score 0.23865562795116085\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I really don't know the answer, please try another one.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Does money have any meanings?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "1ch-gQLNvbDX",
    "outputId": "a5d5532e-c6fc-41f5-9023-016cfc623495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is my favorite place in the world given that you've been to so many places?\n",
      "This is the question similarity score 0.38189729855864274\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.3606760223253399\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I mean, I think the best place in the world is the place that you're in.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"What is your favorite place in the world given that you've been to so many places?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "9u3cAUg0wCU7",
    "outputId": "d4f6a7f5-1191-4bf9-a7cb-ee2586b23889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who do I hate?\n",
      "This is the question similarity score 0.4887275268010272\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.3062214086196605\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The question topic is not in my training data, I don't have the an answer. Apology.\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Who do you hate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "fo64QQl1wHzf",
    "outputId": "393da967-a94e-4a05-b82c-9053b7699cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I have herpes?\n",
      "This is the question similarity score 0.47871997973237546\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.5930058548951\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'No.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"Do you have herpes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "kCB7XPwExk8m",
    "outputId": "9a76c60c-76e5-40fa-82ac-c78e50bbe16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does Jesus like to climb too?\n",
      "This is the question similarity score 0.565287663587178\n",
      "Fact question\n",
      "This is the factual answer similarity score 0.41475016274619847\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_gpt(\"does Jesus like to climb too?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "4j_b4EdrnRwR",
    "outputId": "82611299-4bea-4f7e-965d-30fcfcb287e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Abstract'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_type = openai.Classification.create(\n",
    "    search_model=\"babbage\", \n",
    "    model=\"curie\",\n",
    "    examples=examples,\n",
    "    query=\"why do you love climbing?\",\n",
    "    labels = [\"Factual\",\"Abstract\"],    \n",
    "    max_examples=50)\n",
    "question_type = question_type[\"label\"]\n",
    "question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qk6tbxJprAFE"
   },
   "outputs": [],
   "source": [
    "# Testing without try and except\n",
    "def question_answer(question: str) -> str:\n",
    "  # best model: temp = 0.4, pres pen = -1.5, freq pen = 2.00\n",
    "  qa_answer = openai.Answer.create (\n",
    "      search_model=\"babbage\", \n",
    "      model=\"curie\", \n",
    "      question=question, \n",
    "      file=\"file-mcgwAkzglsZSibNyeFuuGjcH\",\n",
    "      examples_context=\"In 2017, U.S. life expectancy was 78.6 years.\", \n",
    "      examples=[[\"What is human life expectancy in the United States?\", \"78 years.\"]], \n",
    "      max_rerank=200,\n",
    "      max_tokens=25,\n",
    "      temperature=0.4,\n",
    "      stop=[\"\\n\", \"<|endoftext|>\"]\n",
    "  )\n",
    "  qa_answer_parse = qa_answer['answers'][0]\n",
    "  # Acccounting for incomplete answer\n",
    "  if not qa_answer_parse.endswith(\".\"):\n",
    "      qa_answer_x = qa_answer_parse.split(\".\")\n",
    "      return qa_answer_x[0]+'.'\n",
    "  else: \n",
    "    return qa_answer_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QDvmg5ZgGdG"
   },
   "outputs": [],
   "source": [
    "question_answer(\"is a banana a banana?\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "testing_deployment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
