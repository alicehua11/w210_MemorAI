{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjrv7W1ZeSdP"
   },
   "source": [
    "# MemorAI - Word Embedding\n",
    "- Salesken: https://huggingface.co/salesken/query_wellformedness_score\n",
    "- Marvin: https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/final_report.pdf\n",
    "- Query-WellFormedness: https://github.com/google-research-datasets/query-wellformedness\n",
    "- Checklist: https://github.com/marcotcr/checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6CqaigWcKj3"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import output\n",
    "    from google.colab import drive\n",
    "\n",
    "    !pip install gensim==4.0.1\n",
    "    output.clear()\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsQv8QCCegNI",
    "outputId": "0182d5e3-3390-4a4a-b335-5dda0d4907bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "import json\n",
    "import gensim.downloader as gendw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# init\n",
    "nltk.download('punkt')\n",
    "\n",
    "# configs\n",
    "SAVE_MOEL = False\n",
    "MODEL_PATH = '/content/gdrive/MyDrive/Berkeley/W210/w210_Capstone_Project/Repo/memorai/tim/models'\n",
    "\n",
    "# data\n",
    "DOCS = []\n",
    "DOCS.append({\n",
    "'question': '''What do you remember about your spouse?''',\n",
    "'answer': '''I have had more than a little bit of luck in life, but nothing equals in magnitude my marriage to Martin D. Ginsburg. I do not have words adequate to describe my supersmart, exuberant, ever-loving spouse. Early on in our marriage, it became clear to him that cooking was not my strong suit. To the everlasting appreciation of our food-loving children (we became four in 1965, when son James was born), Marty made the kitchen his domain and became Chef Supreme in our home. Marty coached me through the birth of our son, he was the first reader and critic of articles, speeches, and briefs I drafted, and he was at my side constantly, in and out of the hospital, during two long bouts with cancer. And I betray no secret in reporting that, without him, I would not have gained a seat on the U.S. Supreme Court.'''\n",
    "})\n",
    "DOCS.append({\n",
    "'question': '''Who was your best friend? What were they like?''',\n",
    "'answer': '''Justice Antonin Scalia was my best friend. Once asked how we could be friends, given our disagreement on lots of things, Justice Scalia answered: \"I attack ideas. I don't attack people. Some very good people have some very bad ideas. And if you can't separate the two, you gotta get another day job. You don't want to be a judge. At least not a judge on a multi-member panel.\" When we were in India together, we went to Agra to see the Taj Mahal and there is a doorway where you get sight of it. I stood there, when we got there, in that doorway - tears were running down my cheek, it amazed him that I had such an emotional response. I will miss the challenges and the laughter Justice Scalia provoked, his pungent, eminently quotable opinions, so clearly stated that his words never slipped from the reader's grasp, the roses he brought me on my birthday, the chance to appear with him once more as supernumeraries at the opera. He was, indeed, a magnificent performer. How blessed I was to have high spirits, and quick wit. In the words of a duet for tenor Scalia and soprano Ginsburg, we were different, yes, in our interpretation of written texts, yet one in our reverence for the Court and its place in the U.S. system of governance. It was my great good fortune to have known him as a working colleague and treasured friend.'''\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ14Y2Oxq_AR"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVyy7S6PlPff",
    "outputId": "cc89a6c8-0129-49ee-fbbb-6cc887a29224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS:\n",
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n",
      "\n",
      "CORPORA:\n",
      "semeval-2016-2017-task3-subtaskBC\n",
      "semeval-2016-2017-task3-subtaskA-unannotated\n",
      "patent-2017\n",
      "quora-duplicate-questions\n",
      "wiki-english-20171001\n",
      "text8\n",
      "fake-news\n",
      "20-newsgroups\n",
      "__testing_matrix-synopsis\n",
      "__testing_multipart-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "# show pre-trained models & corpora\n",
    "info = gendw.info()\n",
    "# print(json.dumps(info, indent=4))\n",
    "print('MODELS:')\n",
    "for key in info['models'].keys():\n",
    "    print(key)\n",
    "\n",
    "print('\\nCORPORA:')\n",
    "for key in info['corpora'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PEGSe-aHe1p"
   },
   "outputs": [],
   "source": [
    "model = gendw.load(\"glove-wiki-gigaword-50\")\n",
    "# model.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "y7h8zHBxfTfo",
    "outputId": "0a885050-6d49-4d5c-d804-54b343d5c853"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-7001d884501c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'similarity_matrix'"
     ]
    }
   ],
   "source": [
    "model.similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5qfPRB6qWna"
   },
   "outputs": [],
   "source": [
    "def get_keywords_by_count(\n",
    "                docs: List[str], \n",
    "                top: int = 10,\n",
    "                tolist: bool = False) -> pd:\n",
    "    \"\"\"Return a list of top keywords sorted first by alphabetical order and then \n",
    "    by counts.\n",
    "    \"\"\"\n",
    "\n",
    "    def stem_tokens(tokens: List, stemmer: PorterStemmer = PorterStemmer()):\n",
    "        stemmed = []\n",
    "        for item in tokens:\n",
    "            stemmed.append(stemmer.stem(item))\n",
    "        return stemmed\n",
    "\n",
    "    def tokenize(text: str, stemmer: PorterStemmer = PorterStemmer()):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [i for i in tokens if i not in string.punctuation]\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "        return stems\n",
    "\n",
    "    # remove stop words & get count vector\n",
    "    vect = CountVectorizer(\n",
    "                stop_words='english',\n",
    "                # tokenizer=tokenize # optional, default seem to work better\n",
    "    ) \n",
    "    matrix = vect.fit_transform(docs)\n",
    "\n",
    "    # sort & return keywords\n",
    "    counts = pd.DataFrame(\n",
    "                    matrix.toarray(),\n",
    "                    columns=vect.get_feature_names()).T\n",
    "    counts = counts.reset_index()\n",
    "    counts.columns = ['vocb', 'count']\n",
    "    counts = counts.sort_values(by=['count'], ignore_index=True, ascending=False)\n",
    "\n",
    "    if tolist:\n",
    "        return counts.iloc[0:top,]['vocb'].tolist()\n",
    "    else:\n",
    "        return counts.iloc[0:top,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "je9Cyy19KJSj",
    "outputId": "0b000aed-609f-4b7e-ccf0-30a5f7fed43a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marty',\n",
       " 'supreme',\n",
       " 'son',\n",
       " 'loving',\n",
       " 'marriage',\n",
       " 'martin',\n",
       " 'hospital',\n",
       " 'james',\n",
       " 'kitchen',\n",
       " 'life',\n",
       " 'little',\n",
       " 'long',\n",
       " 'luck',\n",
       " 'magnitude',\n",
       " '1965',\n",
       " 'ginsburg',\n",
       " 'reader',\n",
       " 'reporting',\n",
       " 'seat',\n",
       " 'secret']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = DOCS[0]['answer']\n",
    "get_keywords_by_count([doc], 20, tolist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfVRQDuBehAQ"
   },
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XMPqtKKdga6",
    "outputId": "330ddab8-af73-4fba-c24e-c6a5743d86bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38490018, 0.4082483 , 0.33333334, 0.27216554, 0.57735026,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.similarities import Similarity\n",
    "from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile\n",
    "\n",
    "index_tmpfile = get_tmpfile(\"index\")\n",
    "query = [(1, 2), (6, 1), (7, 2)]\n",
    "\n",
    "index = Similarity(index_tmpfile, common_corpus, num_features=len(common_dictionary))  # build the index\n",
    "similarities = index[query]  # get similarities between the query and all index documents\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCvaNbl1gTyE"
   },
   "outputs": [],
   "source": [
    "# train the skip-gram\n",
    "print('Training Word2Vec...')\n",
    "model = Word2Vec(\n",
    "            sentences=nodes_paths, \n",
    "            epochs=10, \n",
    "            vector_size=100, \n",
    "            window=5, \n",
    "            min_count=0, \n",
    "            sg=1, \n",
    "            workers=2)\n",
    "if SAVE_MOEL:\n",
    "    pwd = os.path.dirname(os.path.realpath('__file__'))\n",
    "    save_path = f'{pwd}/models/word2vec.wordvectors' \n",
    "    model.save(save_path)\n",
    "    print(f'Model saved to {save_path}...')\n",
    "\n",
    "# retrieve node embeddings and corresponding subjects\n",
    "node_ids = model.wv.index_to_key  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ")\n",
    "\n",
    "print('Complete!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "word_embedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
